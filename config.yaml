# Model Configuration
models:
  # Simpler models for parallel processing
  model_a:
    provider: "anthropic"
    name: "claude-haiku-4-5"
    temperature: 0.3
    max_tokens: 2000

  model_b:
    provider: "llama"
    name: "Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.3
    max_tokens: 2000

  # Advanced model for supervision (with reasoning)
  model_c:
    provider: "anthropic"
    name: "claude-sonnet-4-5"
    temperature: 0.2
    max_tokens: 4000

  # Advanced model for fact-checking (with reasoning)
  model_d:
    provider: "llama"
    name: "Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.1
    max_tokens: 8000

# Search Tools Configuration
search_tools:
  tavily:
    search_depth: "advanced"
    max_results: 10

  serper:
    num_results: 10

  brave:
    count: 10

# Application Settings
app:
  debug: false
  max_retries: 3
  critic_loops: 2
  stream_delay_ms: 100
