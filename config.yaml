# Model Configuration
models:
  # Supervisor model - Primary: Llama Maverick, Fallback: Claude Haiku
  model_c:
    provider: "llama"
    name: "Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.2
    max_tokens: 4000
    fallback:
      provider: "anthropic"
      name: "claude-haiku-4-5"
      temperature: 0.2
      max_tokens: 4000

  # Fact-checking model - Primary: Llama Maverick, Fallback: Claude Haiku
  model_d:
    provider: "llama"
    name: "Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.1
    max_tokens: 8000
    fallback:
      provider: "anthropic"
      name: "claude-haiku-4-5"
      temperature: 0.1
      max_tokens: 8000

# Search Tools Configuration
search_tools:
  tavily:
    search_depth: "advanced"
    max_results: 10

  serper:
    num_results: 10

  brave:
    count: 10

# Application Settings
app:
  debug: false
  max_retries: 3
  critic_loops: 2
  stream_delay_ms: 100
